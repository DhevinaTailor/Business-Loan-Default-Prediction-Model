{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe05cb9c",
   "metadata": {},
   "source": [
    "---\n",
    "# Predictive Business Loan Default Analysis Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d006c",
   "metadata": {},
   "source": [
    "**Author**: Dhevina Tailor\n",
    "\n",
    "**Contact**: [dhevinatailor@gmail.com](mailto:dhevinatailor@gmail.com)\n",
    "\n",
    "**Date**: November 10, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0782750",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "---\n",
    "1. [Introduction: Data Preprocessing](#introduction)\n",
    "2. [Loading and Setup](#loadingandsetup)\n",
    "3. [Data Assessment and Cleaning](#assessment)\n",
    "4. [Feature Engineering](#feature)\n",
    "5. [Handling Imbalanced Data](#imbalanced)\n",
    "6. [Baseline Modeling](#baseline)\n",
    "7. [Conclusion and Next Steps](#conclusion)\n",
    "8. [Saving the Data](#saving)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e4ffd",
   "metadata": {},
   "source": [
    "## Introduction: Data Preprocessing <a class=\"anchor\" id=\"introduction\"></a>\n",
    "---\n",
    "Data preprocessing is a crucial step in any data science project. It ensures that the dataset is clean, well-structured, and ready for modeling. This phase involves addressing data quality issues, feature engineering, and preparing the dataset for advanced modeling techniques. The accuracy and reliability of predictive models in financial risk assessment heavily depend on the quality of the input data. Therefore, our preprocessing goals include:\n",
    "\n",
    "1. **Data Cleaning**: Rectifying issues such as missing values, outliers, and inconsistencies.\n",
    "2. **Feature Engineering**: Enhancing the dataset with new features or transforming existing ones to improve model performance.\n",
    "3. **Data Transformation**: Including encoding categorical variables, scaling features, and addressing class imbalances.\n",
    "\n",
    "By accomplishing these steps, we lay a solid foundation for building robust and accurate predictive models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141e6b14",
   "metadata": {},
   "source": [
    "## Loading and Setup <a class=\"anchor\" id=\"loadingandsetup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4162c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d9b820",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be634956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"Explored_Loan_Data.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n",
    "\n",
    "# Visualizing the data distribution\n",
    "df.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1394e44e",
   "metadata": {},
   "source": [
    "## Data Assessment and Cleaning <a class=\"anchor\" id=\"assessment\"></a>\n",
    "Our initial assessment focuses on identifying duplicates, irrelevant features, and data inconsistencies. Features like 'City', 'State', and 'Bank' have been dropped due to their high cardinality, which can lead to model overfitting and increased computational complexity. The dataset is then cleaned to remove these columns and any duplicate entries, ensuring data quality and consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b255efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_summary(df):\n",
    "    '''\n",
    "    Basic EDA function\n",
    "    '''\n",
    "    print(f\"Rows: {df.shape[0]}\")\n",
    "    print(f\"Columns: {df.shape[1]}\")\n",
    "    print(f\"Missing values: {df.isna().sum().sum()}\")\n",
    "    print(f\"Duplicated rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80fe6011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 835240\n",
      "Columns: 13\n",
      "Missing values: 0\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "eda_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f20863",
   "metadata": {},
   "source": [
    "Inspecting Categorical columns for unique values prior to creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e31839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in City: 31734\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the number of unique values in the 'City' column.\n",
    "unique_values_count = df['City'].nunique()\n",
    "print(f'Number of unique values in City: {unique_values_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23961ea",
   "metadata": {},
   "source": [
    "Will remove the `City` column since it contains an extensive set of 31,734 unique values to avoid potential overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9050e393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates before dropping 'City': 0\n",
      "Number of duplicates after dropping 'City': 110\n",
      "Sample of duplicated rows:\n",
      "                         Name State                       Bank BankState  \\\n",
      "103480                The Kut    AL  BUSINESS LOAN CENTER, LLC        FL   \n",
      "108351    Aquariumsource, LLC    IL  BUSINESS LOAN CENTER, LLC        FL   \n",
      "122816  J.L.Y COMPUTERS, INC.    IL   CITIZENS BANK NATL ASSOC        RI   \n",
      "138924       Kidz Expressions    NC  BUSINESS LOAN CENTER, LLC        FL   \n",
      "160830             KEYNET INC    NH   CITIZENS BANK NATL ASSOC        NH   \n",
      "\n",
      "         NAICS  NoEmp  NewExist  FranchiseCode  UrbanRural RevLineCr  \\\n",
      "103480  812112      1       1.0              0           1         N   \n",
      "108351  454111      1       2.0              0           1         N   \n",
      "122816  443120      2       1.0              0           1         N   \n",
      "138924  448130      1       2.0              0           1         N   \n",
      "160830  541511      2       1.0              1           0         Y   \n",
      "\n",
      "       MIS_Status  SBA_Appv  \n",
      "103480    Default   21250.0  \n",
      "108351    Default   21250.0  \n",
      "122816    Default   25000.0  \n",
      "138924    Default   21250.0  \n",
      "160830       Paid   25000.0  \n"
     ]
    }
   ],
   "source": [
    "# Display the number of duplicates before any operations\n",
    "print(f\"Number of duplicates before dropping 'City': {df.duplicated().sum()}\")\n",
    "\n",
    "# Drop the 'City' column\n",
    "df = df.drop('City', axis=1)\n",
    "\n",
    "# Check for duplicates after dropping 'City' column\n",
    "duplicates_after_drop = df[df.duplicated()]\n",
    "\n",
    "# Display the number of duplicates after dropping 'City'\n",
    "print(f\"Number of duplicates after dropping 'City': {duplicates_after_drop.shape[0]}\")\n",
    "\n",
    "# Display some of the duplicated rows for inspection\n",
    "print(\"Sample of duplicated rows:\")\n",
    "print(duplicates_after_drop.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145d3c36",
   "metadata": {},
   "source": [
    "To mitigate overfitting, I will be removing redundant entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb0daa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows from the DataFrame\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4f5b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 835130\n",
      "Columns: 12\n",
      "Missing values: 0\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "eda_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5424a0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>SBA_Appv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC HOBBYCRAFT</td>\n",
       "      <td>IN</td>\n",
       "      <td>FIFTH THIRD BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>451120</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LANDMARK BAR &amp; GRILLE (THE)</td>\n",
       "      <td>IN</td>\n",
       "      <td>1ST SOURCE BANK</td>\n",
       "      <td>IN</td>\n",
       "      <td>722410</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>32000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHITLOCK DDS, TODD M.</td>\n",
       "      <td>IN</td>\n",
       "      <td>GRANT COUNTY STATE BANK</td>\n",
       "      <td>IN</td>\n",
       "      <td>621210</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>215250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIG BUCKS PAWN &amp; JEWELRY, LLC</td>\n",
       "      <td>OK</td>\n",
       "      <td>1ST NATL BK &amp; TR CO OF BROKEN</td>\n",
       "      <td>OK</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>28000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANASTASIA CONFECTIONS, INC.</td>\n",
       "      <td>FL</td>\n",
       "      <td>FLORIDA BUS. DEVEL CORP</td>\n",
       "      <td>FL</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>229000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name State                           Bank  \\\n",
       "0                 ABC HOBBYCRAFT    IN               FIFTH THIRD BANK   \n",
       "1    LANDMARK BAR & GRILLE (THE)    IN                1ST SOURCE BANK   \n",
       "2          WHITLOCK DDS, TODD M.    IN        GRANT COUNTY STATE BANK   \n",
       "3  BIG BUCKS PAWN & JEWELRY, LLC    OK  1ST NATL BK & TR CO OF BROKEN   \n",
       "4    ANASTASIA CONFECTIONS, INC.    FL        FLORIDA BUS. DEVEL CORP   \n",
       "\n",
       "  BankState   NAICS  NoEmp  NewExist  FranchiseCode  UrbanRural RevLineCr  \\\n",
       "0        OH  451120      4       2.0              1           0         N   \n",
       "1        IN  722410      2       2.0              1           0         N   \n",
       "2        IN  621210      7       1.0              1           0         N   \n",
       "3        OK       0      2       1.0              1           0         N   \n",
       "4        FL       0     14       1.0              1           0         N   \n",
       "\n",
       "  MIS_Status  SBA_Appv  \n",
       "0       Paid   48000.0  \n",
       "1       Paid   32000.0  \n",
       "2       Paid  215250.0  \n",
       "3       Paid   28000.0  \n",
       "4       Paid  229000.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2bb889d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in State: 51\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the number of unique values in the 'State' column.\n",
    "unique_values_count = df['State'].nunique()\n",
    "print(f'Number of unique values in State: {unique_values_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723379d9",
   "metadata": {},
   "source": [
    "Will remove the `State` column since it contains an extensive set of 51 unique values to avoid potential overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb568fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates before dropping 'State': 0\n",
      "Number of duplicates after dropping 'State': 50\n",
      "Sample of duplicated rows:\n",
      "                                Name                            Bank  \\\n",
      "69178   HORIZON MEDICAL TECHNOLOGIES      BANK OF AMERICA NATL ASSOC   \n",
      "124257                 Candy Bouquet       BUSINESS LOAN CENTER, LLC   \n",
      "157877                   MATCO TOOLS  CITICAPITAL SMALL BUS. FINANCE   \n",
      "182443                   MATCO TOOLS  CITICAPITAL SMALL BUS. FINANCE   \n",
      "194738                  MASSAGE ENVY     BANCO POPULAR NORTH AMERICA   \n",
      "\n",
      "       BankState   NAICS  NoEmp  NewExist  FranchiseCode  UrbanRural  \\\n",
      "69178         WA       0      9       1.0              1           0   \n",
      "124257        FL  445292      1       2.0              0           1   \n",
      "157877        TX       0      1       2.0          52000           0   \n",
      "182443        TX       0      1       2.0          52000           0   \n",
      "194738        NY  621399      2       2.0          51720           1   \n",
      "\n",
      "       RevLineCr MIS_Status  SBA_Appv  \n",
      "69178          Y       Paid   37500.0  \n",
      "124257         N    Default   21250.0  \n",
      "157877         0    Default   44000.0  \n",
      "182443         0    Default   44000.0  \n",
      "194738         Y       Paid   12500.0  \n"
     ]
    }
   ],
   "source": [
    "# Display the number of duplicates before any operations\n",
    "print(f\"Number of duplicates before dropping 'State': {df.duplicated().sum()}\")\n",
    "\n",
    "# Drop the 'State' column\n",
    "df = df.drop('State', axis=1)\n",
    "\n",
    "# Check for duplicates after dropping 'State' column\n",
    "duplicates_after_drop = df[df.duplicated()]\n",
    "\n",
    "# Display the number of duplicates after dropping 'State'\n",
    "print(f\"Number of duplicates after dropping 'State': {duplicates_after_drop.shape[0]}\")\n",
    "\n",
    "# Display some of the duplicated rows for inspection\n",
    "print(\"Sample of duplicated rows:\")\n",
    "print(duplicates_after_drop.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca77c960",
   "metadata": {},
   "source": [
    "To mitigate overfitting, I will be removing redundant entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e951e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows from the DataFrame\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53907df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 835080\n",
      "Columns: 11\n",
      "Missing values: 0\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "eda_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15949e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>SBA_Appv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC HOBBYCRAFT</td>\n",
       "      <td>FIFTH THIRD BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>451120</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LANDMARK BAR &amp; GRILLE (THE)</td>\n",
       "      <td>1ST SOURCE BANK</td>\n",
       "      <td>IN</td>\n",
       "      <td>722410</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>32000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHITLOCK DDS, TODD M.</td>\n",
       "      <td>GRANT COUNTY STATE BANK</td>\n",
       "      <td>IN</td>\n",
       "      <td>621210</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>215250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIG BUCKS PAWN &amp; JEWELRY, LLC</td>\n",
       "      <td>1ST NATL BK &amp; TR CO OF BROKEN</td>\n",
       "      <td>OK</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>28000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANASTASIA CONFECTIONS, INC.</td>\n",
       "      <td>FLORIDA BUS. DEVEL CORP</td>\n",
       "      <td>FL</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>229000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name                           Bank BankState  \\\n",
       "0                 ABC HOBBYCRAFT               FIFTH THIRD BANK        OH   \n",
       "1    LANDMARK BAR & GRILLE (THE)                1ST SOURCE BANK        IN   \n",
       "2          WHITLOCK DDS, TODD M.        GRANT COUNTY STATE BANK        IN   \n",
       "3  BIG BUCKS PAWN & JEWELRY, LLC  1ST NATL BK & TR CO OF BROKEN        OK   \n",
       "4    ANASTASIA CONFECTIONS, INC.        FLORIDA BUS. DEVEL CORP        FL   \n",
       "\n",
       "    NAICS  NoEmp  NewExist  FranchiseCode  UrbanRural RevLineCr MIS_Status  \\\n",
       "0  451120      4       2.0              1           0         N       Paid   \n",
       "1  722410      2       2.0              1           0         N       Paid   \n",
       "2  621210      7       1.0              1           0         N       Paid   \n",
       "3       0      2       1.0              1           0         N       Paid   \n",
       "4       0     14       1.0              1           0         N       Paid   \n",
       "\n",
       "   SBA_Appv  \n",
       "0   48000.0  \n",
       "1   32000.0  \n",
       "2  215250.0  \n",
       "3   28000.0  \n",
       "4  229000.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "296221cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in Bank: 5720\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the number of unique values in the 'Bank' column.\n",
    "unique_values_count = df['Bank'].nunique()\n",
    "print(f'Number of unique values in Bank: {unique_values_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a401ae",
   "metadata": {},
   "source": [
    "Will remove the `Bank` column since it contains an extensive set of 5,720 unique values to avoid potential overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c334aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates before dropping 'Bank': 0\n",
      "Number of duplicates after dropping 'Bank': 29\n",
      "Sample of duplicated rows:\n",
      "                                  Name BankState   NAICS  NoEmp  NewExist  \\\n",
      "140718     Hometown Sleep Center, Inc.        CA  442110      4       1.0   \n",
      "149783  AUTHORIZED DISTRIBUTOR MATCO T        TX       0      1       2.0   \n",
      "149936  AUTHORIZED DISTRIBUTOR MATCO T        TX       0      1       2.0   \n",
      "194874            VENDING OF TEXAS LLC        CA  454210      2       1.0   \n",
      "301172                    Balzer, Inc.        WI  333111     79       1.0   \n",
      "\n",
      "        FranchiseCode  UrbanRural RevLineCr MIS_Status   SBA_Appv  \n",
      "140718              0           1         Y    Default    25000.0  \n",
      "149783          52000           0         0    Default    44000.0  \n",
      "149936          52000           0         0       Paid    44000.0  \n",
      "194874              1           1         0       Paid     8500.0  \n",
      "301172              1           2         Y       Paid  1500000.0  \n"
     ]
    }
   ],
   "source": [
    "# Display the number of duplicates before any operations\n",
    "print(f\"Number of duplicates before dropping 'Bank': {df.duplicated().sum()}\")\n",
    "\n",
    "# Drop the 'Bank' column\n",
    "df = df.drop('Bank', axis=1)\n",
    "\n",
    "# Check for duplicates after dropping 'Bank' column\n",
    "duplicates_after_drop = df[df.duplicated()]\n",
    "\n",
    "# Display the number of duplicates after dropping 'Bank'\n",
    "print(f\"Number of duplicates after dropping 'Bank': {duplicates_after_drop.shape[0]}\")\n",
    "\n",
    "# Display some of the duplicated rows for inspection\n",
    "print(\"Sample of duplicated rows:\")\n",
    "print(duplicates_after_drop.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a338b1b4",
   "metadata": {},
   "source": [
    "To mitigate overfitting, I will be removing redundant entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c837d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows from the DataFrame\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83905755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 835051\n",
      "Columns: 10\n",
      "Missing values: 0\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "eda_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3bafbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>BankState</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>SBA_Appv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC HOBBYCRAFT</td>\n",
       "      <td>OH</td>\n",
       "      <td>451120</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LANDMARK BAR &amp; GRILLE (THE)</td>\n",
       "      <td>IN</td>\n",
       "      <td>722410</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>32000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHITLOCK DDS, TODD M.</td>\n",
       "      <td>IN</td>\n",
       "      <td>621210</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>215250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIG BUCKS PAWN &amp; JEWELRY, LLC</td>\n",
       "      <td>OK</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>28000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANASTASIA CONFECTIONS, INC.</td>\n",
       "      <td>FL</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>229000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name BankState   NAICS  NoEmp  NewExist  \\\n",
       "0                 ABC HOBBYCRAFT        OH  451120      4       2.0   \n",
       "1    LANDMARK BAR & GRILLE (THE)        IN  722410      2       2.0   \n",
       "2          WHITLOCK DDS, TODD M.        IN  621210      7       1.0   \n",
       "3  BIG BUCKS PAWN & JEWELRY, LLC        OK       0      2       1.0   \n",
       "4    ANASTASIA CONFECTIONS, INC.        FL       0     14       1.0   \n",
       "\n",
       "   FranchiseCode  UrbanRural RevLineCr MIS_Status  SBA_Appv  \n",
       "0              1           0         N       Paid   48000.0  \n",
       "1              1           0         N       Paid   32000.0  \n",
       "2              1           0         N       Paid  215250.0  \n",
       "3              1           0         N       Paid   28000.0  \n",
       "4              1           0         N       Paid  229000.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View updated df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1faadf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in BankState: 56\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the number of unique values in the 'BankState'column.\n",
    "unique_values_count = df['BankState'].nunique()\n",
    "print(f'Number of unique values in BankState: {unique_values_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819597fb",
   "metadata": {},
   "source": [
    "Will remove the `BankState` column since it contains an extensive set of 56 unique values to avoid potential overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6a9d5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates before dropping 'BankState': 0\n",
      "Number of duplicates after dropping 'BankState': 129\n",
      "Sample of duplicated rows:\n",
      "                                 Name   NAICS  NoEmp  NewExist  FranchiseCode  \\\n",
      "8751    Speech Technology Associates,  511210      7       2.0              1   \n",
      "40183  NORTHEAST BUILDERS & REMODELER  236118      6       1.0              1   \n",
      "58910             B & B Handbags Inc.  424330      6       1.0              0   \n",
      "81797                 MINUTEMAN PRESS       0      4       1.0          53650   \n",
      "89153       Americus Engineering, LC.  541330      1       1.0              0   \n",
      "\n",
      "       UrbanRural RevLineCr MIS_Status  SBA_Appv  \n",
      "8751            2         N       Paid   50000.0  \n",
      "40183           1         N       Paid   25000.0  \n",
      "58910           1         Y       Paid   25000.0  \n",
      "81797           0         N       Paid   80000.0  \n",
      "89153           1         N    Default   21250.0  \n"
     ]
    }
   ],
   "source": [
    "# Display the number of duplicates before any operations\n",
    "print(f\"Number of duplicates before dropping 'BankState': {df.duplicated().sum()}\")\n",
    "\n",
    "# Drop the 'Bank' column\n",
    "df = df.drop('BankState', axis=1)\n",
    "\n",
    "# Check for duplicates after dropping 'BankState' column\n",
    "duplicates_after_drop = df[df.duplicated()]\n",
    "\n",
    "# Display the number of duplicates after dropping 'BankState'\n",
    "print(f\"Number of duplicates after dropping 'BankState': {duplicates_after_drop.shape[0]}\")\n",
    "\n",
    "# Display some of the duplicated rows for inspection\n",
    "print(\"Sample of duplicated rows:\")\n",
    "print(duplicates_after_drop.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73515a21",
   "metadata": {},
   "source": [
    "To mitigate overfitting, I will be removing redundant entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23b9cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows from the DataFrame\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2b35c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 834922\n",
      "Columns: 9\n",
      "Missing values: 0\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "eda_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7c293bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>SBA_Appv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC HOBBYCRAFT</td>\n",
       "      <td>451120</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LANDMARK BAR &amp; GRILLE (THE)</td>\n",
       "      <td>722410</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>32000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHITLOCK DDS, TODD M.</td>\n",
       "      <td>621210</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>215250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIG BUCKS PAWN &amp; JEWELRY, LLC</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>28000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANASTASIA CONFECTIONS, INC.</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>229000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name   NAICS  NoEmp  NewExist  FranchiseCode  \\\n",
       "0                 ABC HOBBYCRAFT  451120      4       2.0              1   \n",
       "1    LANDMARK BAR & GRILLE (THE)  722410      2       2.0              1   \n",
       "2          WHITLOCK DDS, TODD M.  621210      7       1.0              1   \n",
       "3  BIG BUCKS PAWN & JEWELRY, LLC       0      2       1.0              1   \n",
       "4    ANASTASIA CONFECTIONS, INC.       0     14       1.0              1   \n",
       "\n",
       "   UrbanRural RevLineCr MIS_Status  SBA_Appv  \n",
       "0           0         N       Paid   48000.0  \n",
       "1           0         N       Paid   32000.0  \n",
       "2           0         N       Paid  215250.0  \n",
       "3           0         N       Paid   28000.0  \n",
       "4           0         N       Paid  229000.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View updated df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6fe5d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in NAICS: 1311\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the number of unique values in the 'NAICS' column.\n",
    "unique_values_count = df['NAICS'].nunique()\n",
    "print(f'Number of unique values in NAICS: {unique_values_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44ab8bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([451120, 722410, 621210, ..., 315280, 922140, 221121])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the unique values\n",
    "unique_values = df['NAICS'].unique()\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f49b75",
   "metadata": {},
   "source": [
    "We can categorize this according to each industry so we will not drop the `NAICS` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dde3f3dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in NoEmp: 585\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the number of unique values in the 'NoEmp' column.\n",
    "unique_values_count = df['NoEmp'].nunique()\n",
    "print(f'Number of unique values in NoEmp: {unique_values_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edc95f72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   4,    2,    7,   14,   19,   45,    1,    3,   24,    5,   16,\n",
       "         12,    6,   90,   18,    9,   20,   10,    8,   50,   17,   32,\n",
       "         31,   60,   22,   40,   72,   55,   30,   25,   46,   15,  214,\n",
       "         28,   23,   11,   13,  112,   26,   42,   65,   21,   97,  100,\n",
       "        200,  126,   48,   33,   58,   38,   35,    0,   75,   36,   70,\n",
       "         66,   27, 2000,   56,   34,   93,  150,   29,   41,  290,   67,\n",
       "         44,   47,  119,   39,  155,   54,   49,   82,   95,  300,   51,\n",
       "         80,  120,  265,  133,   86,   37,   68,   61,  220,   43,  160,\n",
       "         71,   98,  350,   78,  233,  263,   62, 7941,   63,  210,  125,\n",
       "        107,  450,   85,  165,  130, 9992,   77,   64,  424,  257,   52,\n",
       "        600,  190,  142,   99,   59,   73,  135,   74,  250,   69,  500,\n",
       "        140,  116,  260,   96,  339,   87,  110,  161,   88,   53,  400,\n",
       "       2725,  605,   57,  103,   91,   81,  147,  144,  175,  136,  182,\n",
       "        156,  118,  375,   94,  345,  121,  145,  105,  180,  101,   84,\n",
       "         89,   76,  550,  216,  108,  138,  117,  249,  171,  279,  208,\n",
       "        170,   79, 9999,  115,  104,   83,  153,  106,  191,  270,  295,\n",
       "       3000,  230,  195,  127,  313,  205,  141,  128,  199,  102,  124,\n",
       "        162,  305,  185,  152,  129,  275,  576,  132,  196,  178,  750,\n",
       "        720,  414,  315,  143,  299,  217,  179,  320, 4000,  167,  114,\n",
       "        203,  134, 8000,  111, 5511, 5921,   92,  240,  280,  148,  340,\n",
       "        285, 1300, 1800,  680,  258,  231,  173,  109, 1980, 5812,  401,\n",
       "        192, 5084,  480,  186,  131,  146,  168, 1050,  189,  343, 7216,\n",
       "        312, 8041,  394,  307, 7389,  174,  828,  485,  266, 2100, 1000,\n",
       "       5947,  368, 1600, 5000, 1500,  298, 6000,  221, 4953,  355,  137,\n",
       "        325,  123,  122,  344,  163,  386,  530,  237,  330,  188,  387,\n",
       "       1003,  761,  421,  113,  308,  158,  310,  187,  238,  235,  222,\n",
       "       7111, 2112,  254, 1200,  225,  228, 2400,  360,  317,  425, 8018,\n",
       "        430,  197,  157,  176,  198,  256, 3200,  183,  277,  362,  202,\n",
       "        289,  139,  520,  154,  177,  316,  224,  149,  151,  215,  395,\n",
       "        262, 6501,  169,  282, 4100,  383,  900,  172,  688,  287, 1250,\n",
       "        390,  318, 4847, 7231, 5149, 3900,  967, 3500,  314,  602,  476,\n",
       "        206, 1461,  408,  441,  246,  336,  570,  227, 1940,  735,  523,\n",
       "        204, 1233, 3170, 1711,  255,  351, 1451,  207,  365,  454, 1550,\n",
       "        823,  544, 1150,  294, 9000,  226, 7000,  463,  211,  370, 2900,\n",
       "       4005, 1900,  241,  288,  194,  213,  278,  484,  281,  322,  650,\n",
       "        181,  521,  218,  800,  420, 3400, 1400,  700,  242, 2200, 2500,\n",
       "        495,  358,  243,  466,  354,  223,  184,  479,  269,  510,  435,\n",
       "        342,  385,  193,  232,  827, 2401,  273,  713,  253,  261,  296,\n",
       "       2501, 1629, 1700,  429, 2010,  455,  660,  164, 1235,  252,  376,\n",
       "        380,  464,  332,  245, 1100,  608,  209,  247, 5555,  329,  604,\n",
       "        456,  166, 1280, 3089,  985, 1020,  505, 1502,  234, 5200,  284,\n",
       "        609,  259,  475,  324, 1981,  323,  251,  740,  575,  396, 1030,\n",
       "        229, 2610,  515,  328,  442,  433, 2232,  341,  306, 3732,  346,\n",
       "        447,  850,  427,  407,  782,  293,  356, 4685,  625,  274,  363,\n",
       "       1005,  369,  458,  267, 7999, 2020,  445, 2121, 1125, 1010, 4658,\n",
       "        712,  212,  271,  377, 1718, 1515,  560,  404,  302,  276,  248,\n",
       "       1015,  268, 3737,  319, 2120,  304,  512,  585,  292,  808,  244,\n",
       "       9090, 3030,  606,  840,  301, 2300, 3600,  159,  525,  353, 7991,\n",
       "       5211, 4012, 1112, 1440,  413, 5680,  410,  488, 3100, 3334,  538,\n",
       "       1603, 2520,  283, 1520, 2202,  357,  201, 1012,  499,  423,  635,\n",
       "       1073,  465, 2510, 1644,  403, 4300,  382,  498,  448, 3009,  685,\n",
       "       1340, 2700,  367,  535,  760, 1524,  309, 7007,  384, 1960,  540,\n",
       "       5013,  780,  348,  717, 7538,  405, 2005, 1382,  640,  858, 9945,\n",
       "       1920, 3713])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the unique values\n",
    "unique_values = df['NoEmp'].unique()\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fdae37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in NewExist: 2\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the number of unique values in the 'NewExist' column.\n",
    "unique_values_count = df['NewExist'].nunique()\n",
    "print(f'Number of unique values in NewExist: {unique_values_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c843e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in FranchiseCode: 719\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the number of unique values in the 'FranchiseCode' column.\n",
    "unique_values_count = df['FranchiseCode'].nunique()\n",
    "print(f'Number of unique values in FranchiseCode: {unique_values_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08cb4254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     0, 22470, 21425, 21400, 23997, 51570, 81612, 81965,\n",
       "       23379, 22475, 21420, 23000, 72590, 71456, 44081, 52000, 21780,\n",
       "       42520, 45455, 81630, 53250, 56480, 62343, 52956, 55120, 61400,\n",
       "       49952,  4516, 56837, 45479, 33570, 61901, 33550, 62753, 61900,\n",
       "       21790, 48450, 31150,  9202, 22678, 81602, 55512, 56885, 52018,\n",
       "       48000, 32074, 55185, 54600, 53165, 45150, 22680, 71658, 21800,\n",
       "       53657, 33750, 22676, 51720, 55960, 45890, 71685, 11245,  2105,\n",
       "       56920, 54100, 45505, 53650, 33170, 52707, 81550, 45100, 72515,\n",
       "       62907, 32077, 81800, 42533, 31243, 45495, 31300, 32195,  5650,\n",
       "       52875, 32130, 55524, 61401, 55193, 61897, 21660, 48260, 33470,\n",
       "       42599, 11250, 21870, 44350, 51778, 31415, 52300, 56880, 52855,\n",
       "        4250, 45955, 44725, 51560,  2357, 56925, 45915, 49855,  9201,\n",
       "       48400, 62346, 62751, 71158, 81597, 54400, 61390, 62100, 42580,\n",
       "       55955, 81570, 53680, 72683, 23375, 62760, 61603, 56575,  6140,\n",
       "       54005, 32125, 42600, 44066, 51702, 52070, 23110, 54010, 44062,\n",
       "       61885, 55815, 21105, 32200,  4417, 56884, 44073, 44890, 32055,\n",
       "       55650, 61391, 21580,  9235, 23540, 54390, 21669, 55513, 55519,\n",
       "       21180, 42629, 42610, 44605, 31241, 72685, 53290, 62360, 81582,\n",
       "       71000, 42620,  4200, 23104, 52900, 48550, 61915, 22375, 42530,\n",
       "       62460, 56800, 61384, 54300, 71010,  6125, 49820, 52225,  2299,\n",
       "       62850, 33155,  4416, 42800, 53162, 61398, 62348, 56230, 81574,\n",
       "       32136, 44045, 31352, 52891, 45300, 31240, 44080, 31249, 81699,\n",
       "       44037, 53310, 55825, 23377, 45145, 81586, 32070, 72215, 31157,\n",
       "       49200, 44006, 44059, 44053, 55680, 45806, 53325, 23115, 61299,\n",
       "       33125, 56818, 53300, 48038, 53145, 52240, 61210, 62150, 71669,\n",
       "       44060, 33560, 81601, 61802, 56400, 31154, 54643, 45496, 48815,\n",
       "       52079, 53160, 72595, 52245, 44040, 81625,  9237, 21735, 48818,\n",
       "       33185,   452,  4252, 61253, 56604, 45919, 48250,  2297, 81610,\n",
       "       71684, 21037, 55510, 44729, 61214, 45970, 81606, 53660,   485,\n",
       "       33150, 71660,  9250, 81566, 55427, 81961, 42483,  4262, 61896,\n",
       "        4509, 52250, 33563, 21169, 32071, 21177, 33485, 61627, 71170,\n",
       "        5649, 55990, 62905, 44065, 53585, 23003,  2354, 51758,  4251,\n",
       "       31225, 44033, 53950, 21585, 21165, 21804,  2107, 32418, 81960,\n",
       "       55430, 42525, 72500, 81555, 81607,  6153, 42000,  6131, 81595,\n",
       "       51956, 44007, 72377, 71194, 44067, 55652, 72990, 31227, 71946,\n",
       "       22368,  9230, 48606, 62950, 81611, 45500, 61389,  9234, 44600,\n",
       "       72495, 52898, 61898, 81614, 56840,  4452, 53316, 49753, 81623,\n",
       "       56221, 51805, 42639, 44009, 71675,  2100,  9246,  9228, 61890,\n",
       "       61906, 49975, 81621, 23122,  9200, 56825, 33165, 71455, 51500,\n",
       "       44072, 71050, 56010, 62752, 49272, 33194, 55190, 54210, 21025,\n",
       "        9227, 44005, 42596, 52004, 22684, 71169, 48256, 52413, 56016,\n",
       "       56821, 72592, 32210, 32053, 32205, 31370,  9233, 52899, 48850,\n",
       "       62756, 42478, 53651, 42468, 62765, 44052, 56600,   420, 48500,\n",
       "        6133, 81790, 71453, 61500, 52265, 62903, 72600, 81603, 81560,\n",
       "       56824,  6139, 62450, 44078, 33210, 71720, 81589, 21428, 22677,\n",
       "       52007, 53700, 81906, 22660,  2367, 55212, 31360, 71947, 56836,\n",
       "       72380, 52414, 81605, 21500,   426, 61895, 81615, 51567, 51721,\n",
       "       71937, 32075, 49830, 55202, 21745, 42475, 21930,  2360, 72599,\n",
       "       71673, 11950, 56810, 32046,  6150, 48800, 45889,  6170, 55950,\n",
       "        9249, 56220, 71670,  2359, 21781, 53286, 23350, 56890, 44015,\n",
       "       42545, 11900, 45140, 53460, 71160, 51950, 11235, 61260, 61397,\n",
       "        5670, 52910, 53295, 55511, 62455, 62990,  4500,  4258, 53905,\n",
       "       42474, 62700, 21900, 55670, 44070, 45912, 22690, 48810, 32060,\n",
       "       52012, 52419, 31414, 21890, 51716, 31252, 55505, 51725, 48032,\n",
       "       61625, 48805, 72690, 71696, 48265, 61290, 61615,  4491, 81580,\n",
       "       56915, 81620, 61275, 81613, 55180, 81554, 51002, 71440, 48610,\n",
       "       33187, 81616, 42540, 32127, 53323, 51003, 62390, 52015, 55214,\n",
       "       44057, 81617, 61000, 71650, 11240, 22679,  9240, 51777, 55210,\n",
       "       44400, 11005, 11397, 11002, 81591, 48390, 52865, 72382, 81608,\n",
       "       48030, 81900, 21700,  4455, 53880, 52903, 61899, 61497, 33166,\n",
       "       53324, 48613, 44627, 21725, 23100, 53714, 81860, 51700, 61385,\n",
       "       32067, 71130,  6142, 22399, 52320, 48378, 32190, 52200, 62340,\n",
       "       21720, 49215, 21605, 32175, 71680, 54625, 81598, 72518, 71950,\n",
       "        9243, 71200, 44050,  2362,   455, 62688, 42625, 42479, 45950,\n",
       "       45465, 22395, 81572, 61250,  4459, 48020, 56223, 33510, 81797,\n",
       "       32299, 55175, 33509, 71205, 56839, 61629, 44008, 31400,  2103,\n",
       "        6130, 71140, 22480, 32050,  5549, 33190, 42631, 71700, 22663,\n",
       "       92000, 71452, 48501, 33215, 56883, 62925, 72594, 61919, 32400,\n",
       "       45105,  4259, 81587,  4256, 61295, 44090, 62750, 51575, 51795,\n",
       "       52948,  4492, 22675,  4457,  9225, 71705, 42586, 44625, 11023,\n",
       "       56819, 11965, 45482, 11150, 31256, 72684, 11299, 61605, 56878,\n",
       "       11195, 11836, 52860, 55220, 45499, 56830, 51733, 61402, 22687,\n",
       "       54200, 61829, 92006, 21430, 21424,  2361, 81575, 48026,  6132,\n",
       "       55215, 48385, 33747, 42597,   482,  4257, 48826, 62900, 23376,\n",
       "       23356, 56450, 53151, 71661, 72681, 54640, 71454, 72678, 44083,\n",
       "       71940, 81584, 61405, 45494, 23352, 31144, 81588, 54630, 31357,\n",
       "         456, 23378, 54610, 53296, 71185, 31363, 45477, 51780, 62349,\n",
       "       42636, 45953,  4254, 54126, 62715, 81830, 62452, 81619,  4495,\n",
       "       72680, 71459, 33567,  4255, 51630, 62855,  4456, 32063, 21038,\n",
       "       48820, 81599, 56574, 23118, 31411, 44572, 53110, 62344])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the unique values\n",
    "unique_values = df['FranchiseCode'].unique()\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cbdeca",
   "metadata": {},
   "source": [
    "Will remove the `FranchiseCode` column since it contains an extensive set of 719 unique values to avoid potential overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8feef410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates before dropping 'FranchiseCode': 0\n",
      "Number of duplicates after dropping 'FranchiseCode': 46\n",
      "Sample of duplicated rows:\n",
      "                                 Name   NAICS  NoEmp  NewExist  UrbanRural  \\\n",
      "43108             DOLLY MADISON, INC.  722110     15       1.0           2   \n",
      "51197  Severy Brothers Property Manag  812990      2       1.0           2   \n",
      "58493     SAMME AUTOMOTIVE GROUP, LLC  811111     10       1.0           1   \n",
      "69056                     MERRY MAIDS       0      1       2.0           0   \n",
      "75603   TAXATION WITH REPRESENTATION,  541219      1       2.0           1   \n",
      "\n",
      "      RevLineCr MIS_Status  SBA_Appv  \n",
      "43108         N       Paid   22500.0  \n",
      "51197         N       Paid    3250.0  \n",
      "58493         Y    Default   12500.0  \n",
      "69056         0       Paid    7750.0  \n",
      "75603         N    Default   12750.0  \n"
     ]
    }
   ],
   "source": [
    "# Display the number of duplicates before any operations\n",
    "print(f\"Number of duplicates before dropping 'FranchiseCode': {df.duplicated().sum()}\")\n",
    "\n",
    "# Drop the 'FranchiseCode' column\n",
    "df = df.drop('FranchiseCode', axis=1)\n",
    "\n",
    "# Check for duplicates after dropping 'FranchiseCode' column\n",
    "duplicates_after_drop = df[df.duplicated()]\n",
    "\n",
    "# Display the number of duplicates after dropping 'FranchiseCode'\n",
    "print(f\"Number of duplicates after dropping 'FranchiseCode': {duplicates_after_drop.shape[0]}\")\n",
    "\n",
    "# Display some of the duplicated rows for inspection\n",
    "print(\"Sample of duplicated rows:\")\n",
    "print(duplicates_after_drop.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70bbad3",
   "metadata": {},
   "source": [
    "To mitigate overfitting, I will be removing redundant entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71a39d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows from the DataFrame\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efa2547d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 834876\n",
      "Columns: 8\n",
      "Missing values: 0\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "eda_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5dbc5991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>SBA_Appv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC HOBBYCRAFT</td>\n",
       "      <td>451120</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LANDMARK BAR &amp; GRILLE (THE)</td>\n",
       "      <td>722410</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>32000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHITLOCK DDS, TODD M.</td>\n",
       "      <td>621210</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>215250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIG BUCKS PAWN &amp; JEWELRY, LLC</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>28000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANASTASIA CONFECTIONS, INC.</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>229000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name   NAICS  NoEmp  NewExist  UrbanRural  \\\n",
       "0                 ABC HOBBYCRAFT  451120      4       2.0           0   \n",
       "1    LANDMARK BAR & GRILLE (THE)  722410      2       2.0           0   \n",
       "2          WHITLOCK DDS, TODD M.  621210      7       1.0           0   \n",
       "3  BIG BUCKS PAWN & JEWELRY, LLC       0      2       1.0           0   \n",
       "4    ANASTASIA CONFECTIONS, INC.       0     14       1.0           0   \n",
       "\n",
       "  RevLineCr MIS_Status  SBA_Appv  \n",
       "0         N       Paid   48000.0  \n",
       "1         N       Paid   32000.0  \n",
       "2         N       Paid  215250.0  \n",
       "3         N       Paid   28000.0  \n",
       "4         N       Paid  229000.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View updated df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae38d366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in UrbanRural: 3\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the number of unique values in the 'UrbanRural' column.\n",
    "unique_values_count = df['UrbanRural'].nunique()\n",
    "print(f'Number of unique values in UrbanRural: {unique_values_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a0f3a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the unique values\n",
    "unique_values = df['UrbanRural'].unique()\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14e2557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in RevLineCr: 3\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the number of unique values in the 'RevLineCr' column.\n",
    "unique_values_count = df['RevLineCr'].nunique()\n",
    "print(f'Number of unique values in RevLineCr: {unique_values_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a2f86f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', '0', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the unique values\n",
    "unique_values = df['RevLineCr'].unique()\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01374a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in MIS_Status: 2\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the number of unique values in the 'MIS_Status' column.\n",
    "unique_values_count = df['MIS_Status'].nunique()\n",
    "print(f'Number of unique values in MIS_Status: {unique_values_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c43ed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 834876\n",
      "Columns: 8\n",
      "Missing values: 0\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "eda_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6209db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in Name: 741337\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display the number of unique values in the 'FranchiseCode' column.\n",
    "unique_values_count = df['Name'].nunique()\n",
    "print(f'Number of unique values in Name: {unique_values_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329c17c1",
   "metadata": {},
   "source": [
    "Will remove the `Name` column since it contains an extensive set of 741,337 unique values to avoid potential overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0324c8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates before dropping 'Name': 0\n",
      "Number of duplicates after dropping 'Name': 213811\n",
      "Sample of duplicated rows:\n",
      "     NAICS  NoEmp  NewExist  UrbanRural RevLineCr MIS_Status  SBA_Appv\n",
      "84       0      4       1.0           0         0       Paid   12500.0\n",
      "86       0      3       1.0           0         0       Paid   12500.0\n",
      "96       0      5       1.0           0         0       Paid   30000.0\n",
      "97       0      3       1.0           0         0       Paid    5000.0\n",
      "118      0      3       1.0           0         0       Paid    5000.0\n"
     ]
    }
   ],
   "source": [
    "# Display the number of duplicates before any operations\n",
    "print(f\"Number of duplicates before dropping 'Name': {df.duplicated().sum()}\")\n",
    "\n",
    "# Drop the 'Name' column\n",
    "df = df.drop('Name', axis=1)\n",
    "\n",
    "# Check for duplicates after dropping 'Name' column\n",
    "duplicates_after_drop = df[df.duplicated()]\n",
    "\n",
    "# Display the number of duplicates after dropping 'Name'\n",
    "print(f\"Number of duplicates after dropping 'Name': {duplicates_after_drop.shape[0]}\")\n",
    "\n",
    "# Display some of the duplicated rows for inspection\n",
    "print(\"Sample of duplicated rows:\")\n",
    "print(duplicates_after_drop.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e66776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows from the DataFrame\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d921ba5",
   "metadata": {},
   "source": [
    "### Dropping Duplicates in the Dataset\n",
    "\n",
    "In the provided dataset snippet, it appears that rows are duplicated, with identical values across various columns, particularly in the industry-specific dummy variables. It seems that businesses from the same industry result in the same dataset entries. Given this pattern, there are valid reasons to drop these duplicates:\n",
    "\n",
    "1. **Redundancy:** The duplicated rows provide redundant information, as the values in all columns are identical except for the \"NoEmp\" column. Keeping them doesn't add any new insights or contribute to the analysis.\n",
    "\n",
    "2. **Data Efficiency:** Removing duplicates improves data efficiency by reducing the dataset size without sacrificing information. This is particularly valuable when working with large datasets.\n",
    "\n",
    "3. **Model Performance:** Duplicates may lead to biased model training and evaluation, as the model could give undue importance to repeated patterns. Removing duplicates helps ensure a fair representation of the data.\n",
    "\n",
    "4. **Data Consistency:** Keeping duplicates may introduce inconsistencies, especially if future data updates include modifications to only one instance of a duplicate. Removing duplicates maintains data consistency.\n",
    "\n",
    "5. **Industry-specific Duplicates:** The observed pattern, where businesses from the same industry have identical values, further reinforces the rationale for dropping duplicates. It appears that businesses from the same industry result in the same dataset entries.\n",
    "\n",
    "Therefore, dropping these duplicates can enhance the quality, efficiency, and reliability of the dataset for further analysis or modeling purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97b71421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 621065\n",
      "Columns: 7\n",
      "Missing values: 0\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "eda_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4a1b714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>SBA_Appv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>451120</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>48000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>722410</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>32000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>621210</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>215250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>28000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>229000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    NAICS  NoEmp  NewExist  UrbanRural RevLineCr MIS_Status  SBA_Appv\n",
       "0  451120      4       2.0           0         N       Paid   48000.0\n",
       "1  722410      2       2.0           0         N       Paid   32000.0\n",
       "2  621210      7       1.0           0         N       Paid  215250.0\n",
       "3       0      2       1.0           0         N       Paid   28000.0\n",
       "4       0     14       1.0           0         N       Paid  229000.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75e4577b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "Empty DataFrame\n",
      "Columns: [NAICS, NoEmp, NewExist, UrbanRural, RevLineCr, MIS_Status, SBA_Appv]\n",
      "Index: []\n",
      "Number of Duplicate Rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in the entire DataFrame\n",
    "duplicates = df.duplicated()\n",
    "\n",
    "# Display rows with duplicates\n",
    "duplicate_rows = df[duplicates]\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicate_rows)\n",
    "\n",
    "# Display the count of duplicates\n",
    "print(\"Number of Duplicate Rows:\", len(duplicate_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f6e3af",
   "metadata": {},
   "source": [
    "## Feature Engineering: Mapping and Dummy Variable Creation <a class=\"anchor\" id=\"feature\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ceb83",
   "metadata": {},
   "source": [
    "### Exploring and Categorizing NAICS Data\n",
    "\n",
    "We aim to explore and categorize businesses based on their NAICS (North American Industry Classification System) codes. The NAICS codes provide a standardized way of classifying businesses into different industries.\n",
    "\n",
    "#### NAICS (North American Industry Classification System)\n",
    "\n",
    "The NAICS codes are numeric representations that classify businesses into specific industry sectors. Each code corresponds to a particular industry or sector.\n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "#### Mapping NAICS Codes to Sectors\n",
    "\n",
    "To make the data more interpretable, we map the numeric NAICS codes to broader industry sectors. This mapping helps create a new 'Sector' column in the DataFrame.\n",
    "\n",
    "#### Creating Dummy Variables\n",
    "\n",
    "We use the `pd.get_dummies` function to create binary dummy variables for each sector. These dummy variables represent the presence or absence of a specific sector for each business.\n",
    "\n",
    "#### Integer Representation\n",
    "\n",
    "To improve readability, we convert the dummy variables to integers (0 or 1) instead of True/False.\n",
    "\n",
    "### Result\n",
    "\n",
    "The final DataFrame includes the original business data along with binary dummy variables representing each sector. Additionally, an 'Undefined Sector' category is used for businesses with unknown or undefined NAICS codes.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This preprocessing step allows for a clearer analysis of businesses based on their industry sectors, providing a foundation for further exploration and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72ac655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create dummy variables from the `NAICS` column. We map the industries in the NAICS column.\n",
    "industry_mapping = {\n",
    "    '11': 'Agriculture',\n",
    "    '21': 'Mining',\n",
    "    '22': 'Utilities',\n",
    "    '23': 'Construction',\n",
    "    '31': 'Manufacturing',\n",
    "    '32': 'Manufacturing',\n",
    "    '33': 'Manufacturing',    \n",
    "    '42': 'Wholesale trade',\n",
    "    '44': 'Retail trade',\n",
    "    '45': 'Retail trade',\n",
    "    '48': 'Transportation',\n",
    "    '49': 'Transportation',\n",
    "    '51': 'Information',\n",
    "    '52': 'Finance and insurance',\n",
    "    '53': 'Real estate',\n",
    "    '54': 'Professional services',\n",
    "    '55': 'Management of companies',\n",
    "    '56': 'Administrative services',\n",
    "    '61': 'Educational services',\n",
    "    '62': 'Healthcare',\n",
    "    '71': 'Arts and recreation',\n",
    "    '72': 'Accommodation and food services',\n",
    "    '81': 'Other services',\n",
    "    '92': 'Public administration',\n",
    "    '00': 'Undefined Industry'\n",
    "}\n",
    "\n",
    "# Create a new 'Industry' column based on the first two digits of 'NAICS'\n",
    "df['Industry'] = df['NAICS'].astype(str).str[:2].map(industry_mapping).fillna('Undefined Industry')\n",
    "\n",
    "# Create dummy variables for the 'Industry' column\n",
    "industry_dummies = pd.get_dummies(df['Industry'], prefix='Industry', drop_first=True)\n",
    "\n",
    "# Concatenate the dummy variables with the original DataFrame\n",
    "df = pd.concat([df, industry_dummies], axis=1)\n",
    "\n",
    "# Convert dummy variables to integer type\n",
    "df[industry_dummies.columns] = df[industry_dummies.columns].astype(int)\n",
    "\n",
    "# Drop the original 'NAICS' and 'Industry' columns\n",
    "df = df.drop(['NAICS', 'Industry'], axis=1)\n",
    "\n",
    "# Now, we have binary dummy variables representing each industry, with 'Undefined Industry;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91d18018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>Industry_Administrative services</th>\n",
       "      <th>Industry_Agriculture</th>\n",
       "      <th>Industry_Arts and recreation</th>\n",
       "      <th>Industry_Construction</th>\n",
       "      <th>...</th>\n",
       "      <th>Industry_Mining</th>\n",
       "      <th>Industry_Other services</th>\n",
       "      <th>Industry_Professional services</th>\n",
       "      <th>Industry_Public administration</th>\n",
       "      <th>Industry_Real estate</th>\n",
       "      <th>Industry_Retail trade</th>\n",
       "      <th>Industry_Transportation</th>\n",
       "      <th>Industry_Undefined Industry</th>\n",
       "      <th>Industry_Utilities</th>\n",
       "      <th>Industry_Wholesale trade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>215250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>229000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NoEmp  NewExist  UrbanRural RevLineCr MIS_Status  SBA_Appv  \\\n",
       "0      4       2.0           0         N       Paid   48000.0   \n",
       "1      2       2.0           0         N       Paid   32000.0   \n",
       "2      7       1.0           0         N       Paid  215250.0   \n",
       "3      2       1.0           0         N       Paid   28000.0   \n",
       "4     14       1.0           0         N       Paid  229000.0   \n",
       "\n",
       "   Industry_Administrative services  Industry_Agriculture  \\\n",
       "0                                 0                     0   \n",
       "1                                 0                     0   \n",
       "2                                 0                     0   \n",
       "3                                 0                     0   \n",
       "4                                 0                     0   \n",
       "\n",
       "   Industry_Arts and recreation  Industry_Construction  ...  Industry_Mining  \\\n",
       "0                             0                      0  ...                0   \n",
       "1                             0                      0  ...                0   \n",
       "2                             0                      0  ...                0   \n",
       "3                             0                      0  ...                0   \n",
       "4                             0                      0  ...                0   \n",
       "\n",
       "   Industry_Other services  Industry_Professional services  \\\n",
       "0                        0                               0   \n",
       "1                        0                               0   \n",
       "2                        0                               0   \n",
       "3                        0                               0   \n",
       "4                        0                               0   \n",
       "\n",
       "   Industry_Public administration  Industry_Real estate  \\\n",
       "0                               0                     0   \n",
       "1                               0                     0   \n",
       "2                               0                     0   \n",
       "3                               0                     0   \n",
       "4                               0                     0   \n",
       "\n",
       "   Industry_Retail trade  Industry_Transportation  \\\n",
       "0                      1                        0   \n",
       "1                      0                        0   \n",
       "2                      0                        0   \n",
       "3                      0                        0   \n",
       "4                      0                        0   \n",
       "\n",
       "   Industry_Undefined Industry  Industry_Utilities  Industry_Wholesale trade  \n",
       "0                            0                   0                         0  \n",
       "1                            0                   0                         0  \n",
       "2                            0                   0                         0  \n",
       "3                            1                   0                         0  \n",
       "4                            1                   0                         0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd0c96ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 621065\n",
      "Columns: 26\n",
      "Missing values: 0\n",
      "Duplicated rows: 175491\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "eda_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041e297",
   "metadata": {},
   "source": [
    "In order to avoid overfitting, I'll be eliminating duplicate entries in the dataset. This step is necessary as it ensures that repeated entries for the same business are removed, reducing redundancy and potential overfitting issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8f249e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows from the DataFrame\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dbe8f4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 445574\n",
      "Columns: 26\n",
      "Missing values: 0\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "eda_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278a9c9b",
   "metadata": {},
   "source": [
    "### `NoEmp` Column\n",
    "The \"NoEmp\" column requires no modifications since it is a numerical column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a26f43a",
   "metadata": {},
   "source": [
    "### Transforming 'NewExist' Column\n",
    "\n",
    "We aim to transform the 'NewExist' column in our DataFrame, which originally contains values representing whether a business is existing or new (1 for existing, 2 for new). This method replaces values in the selected 'NewExist' column. Specifically, it replaces 1 with 0, indicating an existing business, and 2 with 1, indicating a new business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16cd0bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To transform values\n",
    "df['NewExist'] = df['NewExist'].replace({1: 0, 2: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebb562e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>Industry_Administrative services</th>\n",
       "      <th>Industry_Agriculture</th>\n",
       "      <th>Industry_Arts and recreation</th>\n",
       "      <th>Industry_Construction</th>\n",
       "      <th>...</th>\n",
       "      <th>Industry_Mining</th>\n",
       "      <th>Industry_Other services</th>\n",
       "      <th>Industry_Professional services</th>\n",
       "      <th>Industry_Public administration</th>\n",
       "      <th>Industry_Real estate</th>\n",
       "      <th>Industry_Retail trade</th>\n",
       "      <th>Industry_Transportation</th>\n",
       "      <th>Industry_Undefined Industry</th>\n",
       "      <th>Industry_Utilities</th>\n",
       "      <th>Industry_Wholesale trade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>215250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>229000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NoEmp  NewExist  UrbanRural RevLineCr MIS_Status  SBA_Appv  \\\n",
       "0      4       1.0           0         N       Paid   48000.0   \n",
       "1      2       1.0           0         N       Paid   32000.0   \n",
       "2      7       0.0           0         N       Paid  215250.0   \n",
       "3      2       0.0           0         N       Paid   28000.0   \n",
       "4     14       0.0           0         N       Paid  229000.0   \n",
       "\n",
       "   Industry_Administrative services  Industry_Agriculture  \\\n",
       "0                                 0                     0   \n",
       "1                                 0                     0   \n",
       "2                                 0                     0   \n",
       "3                                 0                     0   \n",
       "4                                 0                     0   \n",
       "\n",
       "   Industry_Arts and recreation  Industry_Construction  ...  Industry_Mining  \\\n",
       "0                             0                      0  ...                0   \n",
       "1                             0                      0  ...                0   \n",
       "2                             0                      0  ...                0   \n",
       "3                             0                      0  ...                0   \n",
       "4                             0                      0  ...                0   \n",
       "\n",
       "   Industry_Other services  Industry_Professional services  \\\n",
       "0                        0                               0   \n",
       "1                        0                               0   \n",
       "2                        0                               0   \n",
       "3                        0                               0   \n",
       "4                        0                               0   \n",
       "\n",
       "   Industry_Public administration  Industry_Real estate  \\\n",
       "0                               0                     0   \n",
       "1                               0                     0   \n",
       "2                               0                     0   \n",
       "3                               0                     0   \n",
       "4                               0                     0   \n",
       "\n",
       "   Industry_Retail trade  Industry_Transportation  \\\n",
       "0                      1                        0   \n",
       "1                      0                        0   \n",
       "2                      0                        0   \n",
       "3                      0                        0   \n",
       "4                      0                        0   \n",
       "\n",
       "   Industry_Undefined Industry  Industry_Utilities  Industry_Wholesale trade  \n",
       "0                            0                   0                         0  \n",
       "1                            0                   0                         0  \n",
       "2                            0                   0                         0  \n",
       "3                            1                   0                         0  \n",
       "4                            1                   0                         0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11307cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 445574\n",
      "Columns: 26\n",
      "Missing values: 0\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "eda_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a786f706",
   "metadata": {},
   "source": [
    "### Creating Dummy Variables for `UrbanRural` Column\n",
    "\n",
    "In this code segment, we are generating dummy variables for the 'UrbanRural' column, which categorizes businesses based on their urban or rural locations.\n",
    "\n",
    "- **1 (Urban):** Indicates that the business is located in an urban area.\n",
    "- **2 (Rural):** Indicates that the business is located in a rural area.\n",
    "- **0 (Undefined):** Represents an undefined or missing value.\n",
    "\n",
    "#### Dummy Variable Creation\n",
    "\n",
    "We employ the `pd.get_dummies` function to convert the 'UrbanRural' column into dummy variables. This includes creating dummy variables for the values '1' and '2', representing urban and rural locations, respectively. Additionally, a dummy variable is created for the value '0', signifying undefined or missing information in the original column.\n",
    "\n",
    "#### Concatenation with Original DataFrame\n",
    "\n",
    "The newly generated dummy variables are appended to the original DataFrame, augmenting the dataset with binary columns representing different values of the 'UrbanRural' column.\n",
    "\n",
    "#### Conversion to Integer Type\n",
    "\n",
    "To facilitate analysis and interpretation, the dummy variables are cast to integer type. This ensures that the resulting DataFrame contains 0 or 1 values in the 'UrbanRural' dummy columns.\n",
    "\n",
    "#### Dropping Original 'UrbanRural' Column\n",
    "\n",
    "The original 'UrbanRural' column can be dropped from the DataFrame to avoid redundancy, as the information is now captured by the dummy variables.\n",
    "\n",
    "This process enhances the usability of the categorical data related to urban and rural business locations, making it suitable for various analytical and modeling purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "055866ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for the 'UrbanRural' column, excluding NaN\n",
    "urbanrural_dummies = pd.get_dummies(df['UrbanRural'], prefix='UrbanRural', dummy_na=False)\n",
    "\n",
    "# Concatenate the dummy variables with the original DataFrame\n",
    "df = pd.concat([df, urbanrural_dummies], axis=1)\n",
    "\n",
    "# Convert dummy variables to integer type\n",
    "df[urbanrural_dummies.columns] = df[urbanrural_dummies.columns].astype(int)\n",
    "\n",
    "# Drop the original 'UrbanRural' column if needed\n",
    "df = df.drop(['UrbanRural'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce4ed827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>Industry_Administrative services</th>\n",
       "      <th>Industry_Agriculture</th>\n",
       "      <th>Industry_Arts and recreation</th>\n",
       "      <th>Industry_Construction</th>\n",
       "      <th>Industry_Educational services</th>\n",
       "      <th>...</th>\n",
       "      <th>Industry_Public administration</th>\n",
       "      <th>Industry_Real estate</th>\n",
       "      <th>Industry_Retail trade</th>\n",
       "      <th>Industry_Transportation</th>\n",
       "      <th>Industry_Undefined Industry</th>\n",
       "      <th>Industry_Utilities</th>\n",
       "      <th>Industry_Wholesale trade</th>\n",
       "      <th>UrbanRural_0</th>\n",
       "      <th>UrbanRural_1</th>\n",
       "      <th>UrbanRural_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>215250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Paid</td>\n",
       "      <td>229000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NoEmp  NewExist RevLineCr MIS_Status  SBA_Appv  \\\n",
       "0      4       1.0         N       Paid   48000.0   \n",
       "1      2       1.0         N       Paid   32000.0   \n",
       "2      7       0.0         N       Paid  215250.0   \n",
       "3      2       0.0         N       Paid   28000.0   \n",
       "4     14       0.0         N       Paid  229000.0   \n",
       "\n",
       "   Industry_Administrative services  Industry_Agriculture  \\\n",
       "0                                 0                     0   \n",
       "1                                 0                     0   \n",
       "2                                 0                     0   \n",
       "3                                 0                     0   \n",
       "4                                 0                     0   \n",
       "\n",
       "   Industry_Arts and recreation  Industry_Construction  \\\n",
       "0                             0                      0   \n",
       "1                             0                      0   \n",
       "2                             0                      0   \n",
       "3                             0                      0   \n",
       "4                             0                      0   \n",
       "\n",
       "   Industry_Educational services  ...  Industry_Public administration  \\\n",
       "0                              0  ...                               0   \n",
       "1                              0  ...                               0   \n",
       "2                              0  ...                               0   \n",
       "3                              0  ...                               0   \n",
       "4                              0  ...                               0   \n",
       "\n",
       "   Industry_Real estate  Industry_Retail trade  Industry_Transportation  \\\n",
       "0                     0                      1                        0   \n",
       "1                     0                      0                        0   \n",
       "2                     0                      0                        0   \n",
       "3                     0                      0                        0   \n",
       "4                     0                      0                        0   \n",
       "\n",
       "   Industry_Undefined Industry  Industry_Utilities  Industry_Wholesale trade  \\\n",
       "0                            0                   0                         0   \n",
       "1                            0                   0                         0   \n",
       "2                            0                   0                         0   \n",
       "3                            1                   0                         0   \n",
       "4                            1                   0                         0   \n",
       "\n",
       "   UrbanRural_0  UrbanRural_1  UrbanRural_2  \n",
       "0             1             0             0  \n",
       "1             1             0             0  \n",
       "2             1             0             0  \n",
       "3             1             0             0  \n",
       "4             1             0             0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3020749f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 445574\n",
      "Columns: 28\n",
      "Missing values: 0\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "eda_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46acacc3",
   "metadata": {},
   "source": [
    "### Creating Dummy Variables for `RevLineCr` Column\n",
    "\n",
    "In this code segment, we are generating dummy variables for the 'RevLineCr' column, which signifies the presence or absence of a revolving line of credit for each business.\n",
    "\n",
    "- **Y (Yes):** Indicates that the business has a revolving line of credit.\n",
    "- **N (No):** Indicates that the business does not have a revolving line of credit.\n",
    "- **0 (Undefined):** Represents an undefined or missing value.\n",
    "\n",
    "#### Dummy Variable Creation\n",
    "\n",
    "We use the `pd.get_dummies` function to convert the 'RevLineCr' column into dummy variables. This includes creating a dummy variable for the value '0', which represents undefined or missing information in the original column.\n",
    "\n",
    "#### Concatenation with Original DataFrame\n",
    "\n",
    "The newly generated dummy variables are appended to the original DataFrame, expanding the dataset with binary columns representing different values of the 'RevLineCr' column.\n",
    "\n",
    "#### Conversion to Integer Type\n",
    "\n",
    "To facilitate analysis and interpretation, the dummy variables are cast to integer type. This ensures that the resulting DataFrame contains 0 or 1 values in the 'RevLineCr' dummy columns.\n",
    "\n",
    "#### Dropping Original 'RevLineCr' Column\n",
    "\n",
    "The original 'RevLineCr' column can be dropped from the DataFrame to avoid redundancy, as the information is now captured by the dummy variables.\n",
    "\n",
    "This process enhances the usability of the categorical data related to the presence or absence of revolving lines of credit, making it suitable for various analytical and modeling purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc1d2b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for the 'RevLineCr' column, including '0'\n",
    "revlinecr_dummies = pd.get_dummies(df['RevLineCr'], prefix='RevLineCr')\n",
    "\n",
    "# Concatenate the dummy variables with the original DataFrame\n",
    "df = pd.concat([df, revlinecr_dummies], axis=1)\n",
    "\n",
    "# Convert dummy variables to integer type\n",
    "df[revlinecr_dummies.columns] = df[revlinecr_dummies.columns].astype(int)\n",
    "\n",
    "# Drop the original 'RevLineCr' column if needed\n",
    "df = df.drop(['RevLineCr'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "030870f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>Industry_Administrative services</th>\n",
       "      <th>Industry_Agriculture</th>\n",
       "      <th>Industry_Arts and recreation</th>\n",
       "      <th>Industry_Construction</th>\n",
       "      <th>Industry_Educational services</th>\n",
       "      <th>Industry_Finance and insurance</th>\n",
       "      <th>...</th>\n",
       "      <th>Industry_Transportation</th>\n",
       "      <th>Industry_Undefined Industry</th>\n",
       "      <th>Industry_Utilities</th>\n",
       "      <th>Industry_Wholesale trade</th>\n",
       "      <th>UrbanRural_0</th>\n",
       "      <th>UrbanRural_1</th>\n",
       "      <th>UrbanRural_2</th>\n",
       "      <th>RevLineCr_0</th>\n",
       "      <th>RevLineCr_N</th>\n",
       "      <th>RevLineCr_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Paid</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Paid</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Paid</td>\n",
       "      <td>215250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Paid</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Paid</td>\n",
       "      <td>229000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NoEmp  NewExist MIS_Status  SBA_Appv  Industry_Administrative services  \\\n",
       "0      4       1.0       Paid   48000.0                                 0   \n",
       "1      2       1.0       Paid   32000.0                                 0   \n",
       "2      7       0.0       Paid  215250.0                                 0   \n",
       "3      2       0.0       Paid   28000.0                                 0   \n",
       "4     14       0.0       Paid  229000.0                                 0   \n",
       "\n",
       "   Industry_Agriculture  Industry_Arts and recreation  Industry_Construction  \\\n",
       "0                     0                             0                      0   \n",
       "1                     0                             0                      0   \n",
       "2                     0                             0                      0   \n",
       "3                     0                             0                      0   \n",
       "4                     0                             0                      0   \n",
       "\n",
       "   Industry_Educational services  Industry_Finance and insurance  ...  \\\n",
       "0                              0                               0  ...   \n",
       "1                              0                               0  ...   \n",
       "2                              0                               0  ...   \n",
       "3                              0                               0  ...   \n",
       "4                              0                               0  ...   \n",
       "\n",
       "   Industry_Transportation  Industry_Undefined Industry  Industry_Utilities  \\\n",
       "0                        0                            0                   0   \n",
       "1                        0                            0                   0   \n",
       "2                        0                            0                   0   \n",
       "3                        0                            1                   0   \n",
       "4                        0                            1                   0   \n",
       "\n",
       "   Industry_Wholesale trade  UrbanRural_0  UrbanRural_1  UrbanRural_2  \\\n",
       "0                         0             1             0             0   \n",
       "1                         0             1             0             0   \n",
       "2                         0             1             0             0   \n",
       "3                         0             1             0             0   \n",
       "4                         0             1             0             0   \n",
       "\n",
       "   RevLineCr_0  RevLineCr_N  RevLineCr_Y  \n",
       "0            0            1            0  \n",
       "1            0            1            0  \n",
       "2            0            1            0  \n",
       "3            0            1            0  \n",
       "4            0            1            0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9af06585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 445574\n",
      "Columns: 30\n",
      "Missing values: 0\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "eda_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e7eb9a",
   "metadata": {},
   "source": [
    "### Replacing 'Default' and 'Paid' with Numerical Values in `MIS_Status`\n",
    "\n",
    "The MIS_Status column in the dataset currently contains categorical values, specifically 'Default' and 'Paid'. To facilitate modeling, it's beneficial to convert these categorical values into numerical representations.\n",
    "\n",
    "- The replace method is used on the 'MIS_Status' column.\n",
    "- It takes a dictionary as an argument, where the keys are the values to be replaced ('Default' and 'Paid'), and the values are their corresponding replacements (0 and 1, respectively).\n",
    "- After execution, the 'MIS_Status' column will contain numerical values (0 for 'Default' and 1 for 'Paid')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "adc82202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'default' with 0 and 'paid' with 1 in the 'MIS_Status' column\n",
    "df['MIS_Status'] = df['MIS_Status'].replace({'Default': 0, 'Paid': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8611b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>SBA_Appv</th>\n",
       "      <th>Industry_Administrative services</th>\n",
       "      <th>Industry_Agriculture</th>\n",
       "      <th>Industry_Arts and recreation</th>\n",
       "      <th>Industry_Construction</th>\n",
       "      <th>Industry_Educational services</th>\n",
       "      <th>Industry_Finance and insurance</th>\n",
       "      <th>...</th>\n",
       "      <th>Industry_Transportation</th>\n",
       "      <th>Industry_Undefined Industry</th>\n",
       "      <th>Industry_Utilities</th>\n",
       "      <th>Industry_Wholesale trade</th>\n",
       "      <th>UrbanRural_0</th>\n",
       "      <th>UrbanRural_1</th>\n",
       "      <th>UrbanRural_2</th>\n",
       "      <th>RevLineCr_0</th>\n",
       "      <th>RevLineCr_N</th>\n",
       "      <th>RevLineCr_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>215250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>229000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NoEmp  NewExist  MIS_Status  SBA_Appv  Industry_Administrative services  \\\n",
       "0      4       1.0           1   48000.0                                 0   \n",
       "1      2       1.0           1   32000.0                                 0   \n",
       "2      7       0.0           1  215250.0                                 0   \n",
       "3      2       0.0           1   28000.0                                 0   \n",
       "4     14       0.0           1  229000.0                                 0   \n",
       "\n",
       "   Industry_Agriculture  Industry_Arts and recreation  Industry_Construction  \\\n",
       "0                     0                             0                      0   \n",
       "1                     0                             0                      0   \n",
       "2                     0                             0                      0   \n",
       "3                     0                             0                      0   \n",
       "4                     0                             0                      0   \n",
       "\n",
       "   Industry_Educational services  Industry_Finance and insurance  ...  \\\n",
       "0                              0                               0  ...   \n",
       "1                              0                               0  ...   \n",
       "2                              0                               0  ...   \n",
       "3                              0                               0  ...   \n",
       "4                              0                               0  ...   \n",
       "\n",
       "   Industry_Transportation  Industry_Undefined Industry  Industry_Utilities  \\\n",
       "0                        0                            0                   0   \n",
       "1                        0                            0                   0   \n",
       "2                        0                            0                   0   \n",
       "3                        0                            1                   0   \n",
       "4                        0                            1                   0   \n",
       "\n",
       "   Industry_Wholesale trade  UrbanRural_0  UrbanRural_1  UrbanRural_2  \\\n",
       "0                         0             1             0             0   \n",
       "1                         0             1             0             0   \n",
       "2                         0             1             0             0   \n",
       "3                         0             1             0             0   \n",
       "4                         0             1             0             0   \n",
       "\n",
       "   RevLineCr_0  RevLineCr_N  RevLineCr_Y  \n",
       "0            0            1            0  \n",
       "1            0            1            0  \n",
       "2            0            1            0  \n",
       "3            0            1            0  \n",
       "4            0            1            0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ec2efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a csv file for future use\n",
    "\n",
    "df.to_csv('cleanfeature.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c9e265",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183c9f01",
   "metadata": {},
   "source": [
    "To begin the modeling phase, our initial step involves the assignment of our predictor variables (X) and the target variable (y). In our dataset, the target variable of interest is denoted as `MIS_Status`. Consequently, we will carefully separate this target variable from our set of predictors.\n",
    "\n",
    "In essence, we'll prepare our dataset for the predictive modeling process by isolating the target variable. This strategic separation enables us to construct our models with the necessary distinction between what we aim to predict and the features used for that prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb59e76a",
   "metadata": {},
   "source": [
    "As we embark on the modeling phase of our project, we kick things off by setting the stage for our predictive analysis. Our first order of business is to organize our dataset by separating the independent variables (X) from the target variable (y).\n",
    "\n",
    "In our dataset, the key target variable we're focused on is labeled as `MIS_Status`. So, we'll go ahead and carefully remove this particular variable from the mix. This crucial step lays the groundwork for our modeling process, ensuring that we have a clear distinction between what we're aiming to predict and the variables we're using to make those predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab6e9c0",
   "metadata": {},
   "source": [
    "First we will assign our X and y. Since our target column is `MIS_Status`, we will drop this from X and make it our y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae518d9",
   "metadata": {},
   "source": [
    "### Data Splitting for Model Validation\n",
    "\n",
    "After assigning our features and target variable to X and y, the next crucial step is to perform a train/test split using Scikit-Learn. We have chosen to allocate 20% of the data for the test set.\n",
    "\n",
    "This data division serves a critical purpose in our project. It allows us to segregate the dataset into two distinct sets: the training set and the testing set. The training set is used to train our machine learning model, while the testing set contains data that the model has never encountered during training.\n",
    "\n",
    "The testing set is instrumental in the validation process. It enables us to evaluate our model's performance on previously unseen data, simulating real-world scenarios. This assessment is a vital part of the modeling process, ensuring that our model generalizes well and remains reliable when applied to new, unfamiliar data. It provides a measure of the model's effectiveness and helps confirm its validity for practical applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f53b7988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions in original data:\n",
      "MIS_Status\n",
      "1    0.842325\n",
      "0    0.157675\n",
      "Name: proportion, dtype: float64 \n",
      "\n",
      "Proportions in remainder set:\n",
      "MIS_Status\n",
      "1    0.842302\n",
      "0    0.157698\n",
      "Name: proportion, dtype: float64 \n",
      "\n",
      "Proportions in test set:\n",
      "MIS_Status\n",
      "1    0.842417\n",
      "0    0.157583\n",
      "Name: proportion, dtype: float64 \n",
      "\n",
      "Proportions in train set:\n",
      "MIS_Status\n",
      "1    0.84249\n",
      "0    0.15751\n",
      "Name: proportion, dtype: float64 \n",
      "\n",
      "Proportions in validation set:\n",
      "MIS_Status\n",
      "1    0.841862\n",
      "0    0.158138\n",
      "Name: proportion, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking proportion of data\n",
    "print('Proportions in original data:')\n",
    "print(y.value_counts(normalize=True), '\\n')\n",
    "\n",
    "print('Proportions in remainder set:')\n",
    "print(y_remainder.value_counts(normalize=True), '\\n')\n",
    "\n",
    "print('Proportions in test set:')\n",
    "print(y_test.value_counts(normalize=True), '\\n')\n",
    "\n",
    "print('Proportions in train set:')\n",
    "print(y_train.value_counts(normalize=True), '\\n')\n",
    "\n",
    "print('Proportions in validation set:')\n",
    "print(y_validation.value_counts(normalize=True), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd28cef8",
   "metadata": {},
   "source": [
    "### Data Preparation and Splitting\n",
    "Before modeling, the dataset is first prepared and split into training, validation, and test sets. This is a crucial step in any machine learning pipeline to ensure the model is trained and evaluated properly.\n",
    "\n",
    "1. **Load Data**: The dataset is loaded into `X` and `y`, representing features and the target variable respectively.\n",
    "2. **Splitting Data**: The data is split into different sets:\n",
    "   - `X_remainder` and `X_test` are split from the original dataset, where `X_test` is 20% of the whole dataset.\n",
    "   - `X_train` and `X_validation` are then split from `X_remainder`, with `X_validation` being 30% of `X_remainder`.\n",
    "3. **Data Split Outcome**: This results in three distinct sets for training, validation, and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "101722df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.67      0.36     16911\n",
      "           1       0.91      0.61      0.73     90027\n",
      "\n",
      "    accuracy                           0.62    106938\n",
      "   macro avg       0.57      0.64      0.54    106938\n",
      "weighted avg       0.80      0.62      0.67    106938\n",
      "\n",
      "Confusion Matrix on Validation Set:\n",
      "[[11317  5594]\n",
      " [35467 54560]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "X = df.drop(columns='MIS_Status')\n",
    "y = df['MIS_Status']\n",
    "\n",
    "# Splitting the data into train, validation, and test sets\n",
    "X_remainder, X_test, y_remainder, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_remainder, y_remainder, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e23e3",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "Feature scaling is a method used to standardize the range of independent variables or features of data. It is also a key step in many machine learning algorithms and can significantly impact the performance of a model.\n",
    "\n",
    "1. **StandardScaler**: The `StandardScaler` is used to scale the features to a standard range, often necessary for models like Logistic Regression.\n",
    "2. **Scaling Process**: `X_train` is scaled, and the same scaling parameters are applied to `X_validation` and `X_test` to ensure consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e2e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_validation_scaled = scaler.transform(X_validation)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136634d6",
   "metadata": {},
   "source": [
    "## Handling Imbalanced Data with SMOTE <a class=\"anchor\" id=\"imbalanced\"></a>\n",
    "Imbalanced data can significantly affect model performance, especially in classification problems. SMOTE (Synthetic Minority Over-sampling Technique) is used to balance the dataset.\n",
    "\n",
    "1. **SMOTE Technique**: SMOTE creates synthetic samples from the minority class, making the class distribution more balanced.\n",
    "2. **Applying SMOTE**: SMOTE is applied only to the training data (`X_train_scaled`, `y_train`) to avoid leaking information to the model about the validation and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13756d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling the minority class using SMOTE\n",
    "smote = SMOTE(random_state=1)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7323d8cc",
   "metadata": {},
   "source": [
    "## Baseline Modeling <a class=\"anchor\" id=\"baseline\"></a>\n",
    "We explore several models to establish a baseline performance. The chosen models include Logistic Regression, SVM, and KNN, each with its strengths in handling different aspects of the data. We evaluate these models based on precision, recall, and F1-score to understand their performance in predicting loan defaults."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f9cd8",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation\n",
    "Once the data is prepared and balanced, a model is trained, and its performance is evaluated on the validation set.\n",
    "\n",
    "1. **Logistic Regression Model**: A Logistic Regression model is chosen for its simplicity and effectiveness in binary classification tasks.\n",
    "2. **Model Training**: The model is trained on the balanced training set.\n",
    "3. **Evaluation on Validation Set**: The model's performance is then evaluated on the untouched validation set, providing insight into how well it might perform on unseen data.\n",
    "4. **Metrics**: Classification report and confusion matrix are used to assess the model's performance, giving a detailed view of its precision, recall, and ability to correctly classify instances of each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7eeb82db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.67      0.36     16911\n",
      "           1       0.91      0.61      0.73     90027\n",
      "\n",
      "    accuracy                           0.62    106938\n",
      "   macro avg       0.57      0.64      0.54    106938\n",
      "weighted avg       0.80      0.62      0.67    106938\n",
      "\n",
      "Confusion Matrix on Validation Set:\n",
      "[[11317  5594]\n",
      " [35467 54560]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Model Evaluation on Validation Set\n",
    "predictions = log_reg.predict(X_validation_scaled)\n",
    "print(\"Classification Report on Validation Set:\")\n",
    "print(classification_report(y_validation, predictions))\n",
    "print(\"Confusion Matrix on Validation Set:\")\n",
    "print(confusion_matrix(y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ac8cd5",
   "metadata": {},
   "source": [
    "#### Classification Report\n",
    "1. Precision and Recall for Class 0 (Predicting Defaults)\n",
    "- Precision (0.24): Out of all the instances where the model predicted a loan default (class 0), only 24% were actually defaults. This is a low precision rate.\n",
    "- Recall (0.67): Of all the actual loan defaults, the model correctly identified 67%. This is a fairly high recall, indicating the model is better at identifying actual defaults than avoiding false alarms.\n",
    "\n",
    "2. Precision and Recall for Class 1 (Non-Defaults)\n",
    "\n",
    "- Precision (0.91): The model is highly precise in predicting non-defaults; 91% of its predictions in this class are correct.\n",
    "- Recall (0.61): The model correctly identifies 61% of the actual non-defaults.\n",
    "\n",
    "3. Accuracy (0.62): Overall, the model correctly predicts the outcome 62% of the time.\n",
    "<br>\n",
    "\n",
    "4. Macro Average F1-Score (0.54): This metric averages the F1-scores of both classes. It shows the model's balanced performance across the classes, which is moderate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f6578",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM) Model\n",
    "\n",
    "In this section, we use a Support Vector Machine (SVM) for our classification task. SVM is known for its effectiveness in high-dimensional spaces and its versatility through the use of different kernel functions.\n",
    "\n",
    "- **Model Training**: We train an SVM with a linear kernel, as it is well-suited for binary classification tasks and can be more computationally efficient compared to other kernels.\n",
    "- **Model Evaluation**: After training, we evaluate the SVM on the validation set. The evaluation metrics include precision, recall, and the F1-score, which provide insights into the model's performance, particularly its ability to correctly classify loan defaults.\n",
    "\n",
    "The choice of a linear kernel is driven by the nature of our dataset and the goal to maintain a balance between model complexity and performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7f02f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM Model\n",
    "svm_model = SVC(kernel='linear', random_state=1)\n",
    "svm_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "svm_predictions = svm_model.predict(X_validation_scaled)\n",
    "print(\"SVM Classification Report on Validation Set:\")\n",
    "print(classification_report(y_validation, svm_predictions))\n",
    "print(\"SVM Confusion Matrix on Validation Set:\")\n",
    "print(confusion_matrix(y_validation, svm_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4aefe4",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN) Model\n",
    "\n",
    "Next, we explore the K-Nearest Neighbors (KNN) algorithm for our predictive model. KNN is a simple, non-parametric method that predicts the class of a data point based on the majority class among its 'k' nearest neighbors.\n",
    "\n",
    "- **Model Training**: We set the number of neighbors (`n_neighbors`) in our KNN model. The choice of 'k' is crucial as it determines the extent to which the model captures the underlying patterns in the data.\n",
    "- **Model Evaluation**: The performance of the KNN model is then assessed on the validation set using precision, recall, and F1-score. These metrics help us understand the model's ability to generalize and accurately classify data points, especially in the context of loan default prediction.\n",
    "\n",
    "KNN is particularly interesting for our dataset as it allows us to capture the influence of similar data points (nearest neighbors) in predicting loan defaults.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a656fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KNN Model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=2)\n",
    "knn_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "knn_predictions = knn_model.predict(X_validation_scaled)\n",
    "print(\"KNN Classification Report on Validation Set:\")\n",
    "print(classification_report(y_validation, knn_predictions))\n",
    "print(\"KNN Confusion Matrix on Validation Set:\")\n",
    "print(confusion_matrix(y_validation, knn_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "348a6950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.46      0.28     16911\n",
      "           1       0.87      0.66      0.75     90027\n",
      "\n",
      "    accuracy                           0.62    106938\n",
      "   macro avg       0.53      0.56      0.51    106938\n",
      "weighted avg       0.76      0.62      0.67    106938\n",
      "\n",
      "KNN Confusion Matrix on Validation Set:\n",
      "[[ 7710  9201]\n",
      " [30928 59099]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KNN Model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "knn_predictions = knn_model.predict(X_validation_scaled)\n",
    "print(\"KNN Classification Report on Validation Set:\")\n",
    "print(classification_report(y_validation, knn_predictions))\n",
    "print(\"KNN Confusion Matrix on Validation Set:\")\n",
    "print(confusion_matrix(y_validation, knn_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafd63ef",
   "metadata": {},
   "source": [
    "#### KNN Classification Report\n",
    "1. Class 0 (Defaults)\n",
    "\n",
    "- Precision (0.20): Out of all the instances the model predicted as defaults, only 20% were actually defaults. This indicates a high rate of false positives.\n",
    "- Recall (0.46): The model correctly identified 46% of the actual defaults. This is better than the Logistic Regression model in your previous results but still indicates a significant number of missed defaults.\n",
    "\n",
    "2. Class 1 (Non-Defaults)\n",
    "\n",
    "- Precision (0.87): High precision suggests that the model is effective at predicting non-defaults correctly.\n",
    "- Recall (0.66): The model correctly identifies 66% of the actual non-defaults, indicating that it misses around one-third of the non-default cases.\n",
    "\n",
    "3. Accuracy (0.62): The overall accuracy is the same as the Logistic Regression model, correctly predicting the outcome 62% of the time.\n",
    "<br>\n",
    "\n",
    "4. Macro Average F1-Score (0.51): This average F1-score suggests moderate performance across both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f0251",
   "metadata": {},
   "source": [
    "As of now, Logistic Regression seems to be the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc433f3",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps <a class=\"anchor\" id=\"conclusion\"></a>\n",
    "\n",
    "In this project, we conducted extensive data preprocessing, feature engineering, and developed baseline models for predicting loan defaults. Moving forward, we will focus on refining our models through hyperparameter tuning, experimenting with ensemble methods, and exploring advanced techniques like deep learning. Our goal is to enhance model performance while ensuring they are robust and reliable for practical applications in financial risk assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8580f15",
   "metadata": {},
   "source": [
    "## Saving the Data <a class=\"anchor\" id=\"saving\"></a>\n",
    "Now that we have spent the time modeling this dataset, we are going to save it for future use. We will be using our dataset to carry out further modeling work to learn more about the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac9a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to a csv file for future use\n",
    "\n",
    "df.to_csv('Modeled_Loan_Data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basicpythonkernel",
   "language": "python",
   "name": "basicpythonkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
